{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"NLP_2_tagging.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"hNM7AfounS7C","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1603617891597,"user_tz":-180,"elapsed":27922,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"a41be660-3480-46e2-cf58-4cbea022b68f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DmgabaWMCkSj"},"source":["### evaluation_ner.py"]},{"cell_type":"code","metadata":{"id":"L73B-tjWCadj"},"source":["from collections import OrderedDict\n","\n","def _update_chunk(candidate, prev, current_tag, current_chunk, current_pos, prediction=False):\n","    if candidate == 'B-' + current_tag:\n","        if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n","                current_chunk[-1].append(current_pos - 1)\n","        current_chunk.append([current_pos])\n","    elif candidate == 'I-' + current_tag:\n","        if prediction and (current_pos == 0 or current_pos > 0 and prev.split('-', 1)[-1] != current_tag):\n","            current_chunk.append([current_pos])\n","        if not prediction and (current_pos == 0 or current_pos > 0 and prev == 'O'):\n","            current_chunk.append([current_pos])\n","    elif current_pos > 0 and prev.split('-', 1)[-1] == current_tag:\n","        if len(current_chunk) > 0:\n","            current_chunk[-1].append(current_pos - 1)\n","\n","def _update_last_chunk(current_chunk, current_pos):\n","    if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n","        current_chunk[-1].append(current_pos - 1)\n","\n","def _tag_precision_recall_f1(tp, fp, fn):\n","    precision, recall, f1 = 0, 0, 0\n","    if tp + fp > 0:\n","        precision = tp / (tp + fp) * 100\n","    if tp + fn > 0:\n","        recall = tp / (tp + fn) * 100\n","    if precision + recall > 0:\n","        f1 = 2 * precision * recall / (precision + recall)\n","    return precision, recall, f1\n","\n","def _aggregate_metrics(results, total_correct):\n","    total_true_entities = 0\n","    total_predicted_entities = 0\n","    total_precision = 0\n","    total_recall = 0\n","    total_f1 = 0\n","    for tag, tag_metrics in results.items():\n","        n_pred = tag_metrics['n_predicted_entities']\n","        n_true = tag_metrics['n_true_entities']\n","        total_true_entities += n_true\n","        total_predicted_entities += n_pred\n","        total_precision += tag_metrics['precision'] * n_pred\n","        total_recall += tag_metrics['recall'] * n_true\n","    accuracy = total_correct / total_true_entities * 100\n","    total_precision = total_precision / total_predicted_entities if total_predicted_entities != 0 else 0\n","    total_recall = total_recall / total_true_entities\n","    if total_precision + total_recall > 0:\n","        if total_precision + total_recall >= 1e-16:\n","            total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall)\n","        else:\n","            total_f1 = 0\n","    return total_true_entities, total_predicted_entities, \\\n","           total_precision, total_recall, total_f1, accuracy\n","\n","def _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct):\n","    print('processed {len} tokens ' \\\n","          'with {tot_true} phrases; ' \\\n","          'found: {tot_pred} phrases; ' \\\n","          'correct: {tot_cor}.\\n'.format(len=n_tokens,\n","                                         tot_true=total_true_entities,\n","                                         tot_pred=total_predicted_entities,\n","                                         tot_cor=total_correct))\n","\n","def _print_metrics(accuracy, total_precision, total_recall, total_f1):\n","    print('precision:  {tot_prec:.2f}%; ' \\\n","          'recall:  {tot_recall:.2f}%; ' \\\n","          'F1:  {tot_f1:.2f}\\n'.format(acc=accuracy,\n","                                           tot_prec=total_precision,\n","                                           tot_recall=total_recall,\n","                                           tot_f1=total_f1))\n","\n","def _print_tag_metrics(tag, tag_results):\n","    print(('\\t%12s' % tag) + ': precision:  {tot_prec:6.2f}%; ' \\\n","                               'recall:  {tot_recall:6.2f}%; ' \\\n","                               'F1:  {tot_f1:6.2f}; ' \\\n","                               'predicted:  {tot_predicted:4d}\\n'.format(tot_prec=tag_results['precision'],\n","                                                                         tot_recall=tag_results['recall'],\n","                                                                         tot_f1=tag_results['f1'],\n","                                                                         tot_predicted=tag_results['n_predicted_entities']))\n","\n","class ScoreEvaluator:\n","\tdef __init__(self, token_to_idx, idx_to_tag, idx_to_token):\n","\t\tself.token_to_idx = token_to_idx\n","\t\tself.idx_to_tag = idx_to_tag\n","\t\tself.idx_to_token = idx_to_token\n","\n","\t@staticmethod\n","\tdef precision_recall_f1(y_true, y_pred, print_results=True, short_report=False):\n","\t    # Find all tagy_trues\n","\t    tags = sorted(set(tag[2:] for tag in y_true + y_pred if tag != 'O'))\n","\n","\t    results = OrderedDict((tag, OrderedDict()) for tag in tags)\n","\t    n_tokens = len(y_true)\n","\t    total_correct = 0\n","\n","\t    # For eval_conll_try we find all chunks in the ground truth and prediction\n","\t    # For each chunk we store starting and ending indices\n","\t    for tag in tags:\n","\t        true_chunk = list()\n","\t        predicted_chunk = list()\n","\t        for position in range(n_tokens):\n","\t            _update_chunk(y_true[position], y_true[position - 1], tag, true_chunk, position)\n","\t            _update_chunk(y_pred[position], y_pred[position - 1], tag, predicted_chunk, position, True)\n","\n","\t        _update_last_chunk(true_chunk, position)\n","\t        _update_last_chunk(predicted_chunk, position)\n","\n","\t        # Then we find all correctly classified intervals\n","\t        # True positive results\n","\t        tp = sum(chunk in predicted_chunk for chunk in true_chunk)\n","\t        total_correct += tp\n","\n","\t        # And then just calculate errors of the first and second kind\n","\t        # False negative\n","\t        fn = len(true_chunk) - tp\n","\t        # False positive\n","\t        fp = len(predicted_chunk) - tp\n","\t        precision, recall, f1 = _tag_precision_recall_f1(tp, fp, fn)\n","\n","\t        results[tag]['precision'] = precision\n","\t        results[tag]['recall'] = recall\n","\t        results[tag]['f1'] = f1\n","\t        results[tag]['n_predicted_entities'] = len(predicted_chunk)\n","\t        results[tag]['n_true_entities'] = len(true_chunk)\n","\n","\t    total_true_entities, total_predicted_entities, \\\n","\t           total_precision, total_recall, total_f1, accuracy = _aggregate_metrics(results, total_correct)\n","\n","\t    if print_results:\n","\t        _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct)\n","\t        _print_metrics(accuracy, total_precision, total_recall, total_f1)\n","\n","\t        if not short_report:\n","\t            for tag, tag_results in results.items():\n","\t                _print_tag_metrics(tag, tag_results)\n","\t    if short_report:\n","\t    \tresults = {\n","\t            'precision': total_precision,\n","\t            'recall': total_recall,\n","\t            'f1': total_f1,\n","\t            'n_predicted_entities': total_predicted_entities,\n","\t            'n_true_entities': total_true_entities,\n","\t    \t}\n","\t    return results\n","\n","\tdef predict_tags(self, model, token_idxs_batch):\n","\t    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n","\t    \n","\t    tag_idxs_batch = model.predict_for_batch(token_idxs_batch)\n","\t    tags_batch, tokens_batch = [], []\n","\t    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n","\t        tags, tokens = [], []\n","\t        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\n","\t            if token_idx != self.token_to_idx['<PAD>']:\n","\t                tags.append(self.idx_to_tag[tag_idx])\n","\t                tokens.append(self.idx_to_token[token_idx])\n","\t        tags_batch.append(tags)\n","\t        tokens_batch.append(tokens)\n","\t    return tags_batch, tokens_batch\n","\t    \n","\tdef eval_conll(self, model, data_loader, print_results=False, short_report=True):\n","\t    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n","\t    \n","\t    y_true, y_pred = [], []\n","\t    for x_batch, y_batch in data_loader:\n","\t        pred_tags_batch, tokens_batch = self.predict_tags(model, x_batch)\n","\t        ground_truth_tags = [\n","\t        \t[self.idx_to_tag[tag_idx] for tag_idx in true_tag_sequence][:len(pred_tag_sequence)]\n","\t        \tfor true_tag_sequence, pred_tag_sequence in zip(y_batch, pred_tags_batch)\n","\t        ]\n","\n","\t        # We extend every prediction and ground truth sequence with 'O' tag\n","\t        # to indicate a possible end of entity.\n","\t        for true_sequence, pred_sequence in zip(ground_truth_tags, pred_tags_batch):\n","\t            y_true += true_sequence + ['O']\n","\t            y_pred += pred_sequence + ['O']\n","\n","\t    results = self.precision_recall_f1(y_true, y_pred, print_results=print_results, short_report=short_report)\n","\t    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3wzFzKOCWA6"},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXEdxnHrCWA_"},"source":["def read_data(file_path):\n","    tokens = []\n","    tags = []\n","    temp_token = []\n","    temp_tags = []\n","    i = 0\n","    with open(file_path) as f:\n","      for line in f:\n","        i+=1\n","        #print(line)\n","        if (line == \"\\n\"):\n","          tokens.append(temp_token)\n","          tags.append(temp_tags)\n","          temp_token = []\n","          temp_tags = []\n","        else:\n","\n","          arr = line.split()\n","          #print(arr)\n","          try:\n","            elem = arr[0]\n","          except:\n","            raise Exception(i)\n","          if (arr[0][0] == \"@\"):\n","            elem = \"<USR>\"\n","          if (arr[0].startswith(\"http://\") or arr[0].startswith(\"https://\")):\n","            elem = \"<URL>\"\n","          \n","          temp_token.append(elem)\n","          temp_tags.append(arr[1])\n","\n","\n","\n","    \n","\n","    ######################################\n","    ######### YOUR CODE HERE #############\n","    ######################################\n","    \n","    return tokens, tags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ld1JlVchCWBD"},"source":["train_sentences, train_tags = read_data('/content/drive/My Drive/twitter_ner_data.zip (Unzipped Files)/data/train.txt')\n","val_sentences, val_tags = read_data('/content/drive/My Drive/twitter_ner_data.zip (Unzipped Files)/data/validation.txt')\n","test_sentences, test_tags = read_data('/content/drive/My Drive/twitter_ner_data.zip (Unzipped Files)/data/test.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgMq0tBWpLgZ"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9ETUofgCWBG","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1603617916175,"user_tz":-180,"elapsed":2420,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"6516d5ac-bafc-40de-99fd-b53e0fb5e674"},"source":["for i in range(3):\n","    for token, one_tag in zip(train_sentences[i], train_tags[i]):\n","        print('%s\\t%s' % (token, one_tag))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RT\tO\n","<USR>\tO\n",":\tO\n","Online\tO\n","ticket\tO\n","sales\tO\n","for\tO\n","Ghostland\tB-musicartist\n","Observatory\tI-musicartist\n","extended\tO\n","until\tO\n","6\tO\n","PM\tO\n","EST\tO\n","due\tO\n","to\tO\n","high\tO\n","demand\tO\n",".\tO\n","Get\tO\n","them\tO\n","before\tO\n","they\tO\n","sell\tO\n","out\tO\n","...\tO\n","\n","Apple\tB-product\n","MacBook\tI-product\n","Pro\tI-product\n","A1278\tI-product\n","13.3\tI-product\n","\"\tI-product\n","Laptop\tI-product\n","-\tI-product\n","MD101LL/A\tI-product\n","(\tO\n","June\tO\n",",\tO\n","2012\tO\n",")\tO\n","-\tO\n","Full\tO\n","read\tO\n","by\tO\n","eBay\tB-company\n","<URL>\tO\n","<URL>\tO\n","\n","Happy\tO\n","Birthday\tO\n","<USR>\tO\n","!\tO\n","May\tO\n","Allah\tB-person\n","s.w.t\tO\n","bless\tO\n","you\tO\n","with\tO\n","goodness\tO\n","and\tO\n","happiness\tO\n",".\tO\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ETMhQ7nECWBK"},"source":["def build_dict(entities, special_entities):\n","    \"\"\"\n","    Args:\n","        entities: a list of lists of tokens or tags\n","        special_entities: some special tokens\n","        \n","    Returns:\n","        entity_to_idx : mapping to index  \n","        idx_to_entity : mapping from index\n","    \"\"\"\n","\n","    entity_to_idx = dict()\n","    idx_to_entity = []\n","\n","\n","\n","    \n","    # Create mappings from tokens to indices and vice versa\n","    # Add special tokens to dictionaries\n","    # The first special token must have index 0\n","\n","    #PAD_length = max(len(elem) for elem in entities)\n","    for i in entities:\n","      for j in i:\n","        if j not in idx_to_entity:\n","          idx_to_entity.append(j)\n","\n","    idx_to_entity = special_entities + idx_to_entity\n","    entity_to_idx = {word: i for i, word in enumerate(idx_to_entity)}\n","    ######################################\n","    ######### YOUR CODE HERE #############\n","    ######################################\n","    \n","    return entity_to_idx, idx_to_entity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDiAahusCWBN"},"source":["special_tokens = ['<UNK>', '<PAD>']\n","special_tags = []\n","\n","# Create dictionaries \n","token_to_idx, idx_to_token = build_dict(train_sentences + val_sentences, special_tokens)\n","tag_to_idx, idx_to_tag = build_dict(train_tags, special_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzHF048RCWBR"},"source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","class TaggingDataset(Dataset):\n","    \n","    def __init__(self, sentences, tags, token_to_idx, tag_to_idx):\n","        \"\"\"\n","        Args:\n","            sentences: a list of lists of tokens or tags\n","            tags: some special tokens\n","            token_to_idx: mapping from token to token indexes\n","            tag_to_idx: mapping from tag to tag indexes\n","        \"\"\"\n","        super().__init__()\n","        self._sentences = [ list([ j if j in token_to_idx else \"<UNK>\" for j in l ]) for l in sentences ]\n","        self._tags = tags\n","        self._token_to_idx = token_to_idx\n","        self._tag_to_idx = tag_to_idx\n","        \n","        \n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################\n","        \n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Args:\n","            idx : int\n","            \n","        Returns:\n","            sentence_idx : torch.tensor of token indexes\n","            tag_idx : torch.tensor of tag indexes\n","        \"\"\"\n","\n","        #print(len(self._sentences[idx]))\n","        #print(len(self._tags[idx]))\n","\n","        #print(\"After\")\n","        tokens = torch.Tensor([self._token_to_idx[i] for i in self._sentences[idx]]).int()\n","        #print(self._sentences[idx])\n","        tags = torch.Tensor([self._tag_to_idx[i] for i in self._tags[idx]]).int()\n","        #print(tokens.size())\n","        #print(tags.size())\n","        return tokens, tags \n","        \n","\n","\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################\n","    \n","    def __len__(self):\n","      return len(self._sentences)\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5phmICABsjc"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"487VUzd0CWBU"},"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class PaddingCollator:\n","    def __init__(self,  pad_token_id, pad_tag_id, batch_first=True):\n","        self.pad_token_idx = pad_token_id\n","        self.pad_tag_id = pad_tag_id\n","        self.batch_first = batch_first\n","        \n","    def __call__(self, batch):\n","        \"\"\"\n","        Args:\n","            batch: list of tuples of torch.tensors\n","        \n","        Returns:\n","            new_sentences: torch.tensor\n","            new_tags: torch.tensor\n","                Both tensors have the same size \n","        \"\"\"\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################\n","       \n","        token,tag = zip(*batch)\n","        token_pad = pad_sequence(token, self.batch_first, self.pad_token_idx)\n","        tag_pad =  pad_sequence(tag,self.batch_first,self.pad_tag_id)\n","\n","        return token_pad.long(), tag_pad.long()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mzsd-vCUCWBX"},"source":["small_dataset = TaggingDataset(\n","    sentences=train_sentences[:7],\n","    tags=train_tags[:7],\n","    token_to_idx=token_to_idx,\n","    tag_to_idx=tag_to_idx,\n",")\n","\n","small_loader = DataLoader(\n","    small_dataset,\n","    batch_size=3,\n","    shuffle=False,\n","    drop_last=False,\n","    collate_fn=PaddingCollator(\n","        pad_token_id=token_to_idx['<PAD>'],\n","        pad_tag_id=tag_to_idx['O'],\n","        batch_first=True,\n","    ),\n",")\n","\n","batch_lengths = [3, 3, 1]\n","sequence_lengths = [26, 25, 8]\n","some_pad_tensor = torch.LongTensor([token_to_idx['<PAD>']] * 12)\n","some_outside_tensor = torch.LongTensor([[tag_to_idx['O']] * 12])\n","\n","for i, (tokens_batch, tags_batch) in enumerate(small_loader):\n","    assert tokens_batch.dtype == torch.int64, 'tokens_batch is not LongTensor'\n","    assert tags_batch.dtype == torch.int64, 'tags_batch is not LongTensor'\n","    \n","    assert len(tokens_batch) == batch_lengths[i], 'wrong batch length'\n","    \n","    for one_token_sequence in tokens_batch:\n","        assert len(one_token_sequence) == sequence_lengths[i], 'wrong length of sequence in batch'\n","    \n","    if i == 0:\n","        assert torch.all(tokens_batch[2][-12:] == some_pad_tensor), \"wrong padding\"       \n","        assert torch.all(tags_batch[2][-12:] == some_outside_tensor), \"wrong O tag\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDWoLVUOCWBb"},"source":["######################################\n","######### YOUR CODE HERE #############\n","######################################\n","#  TRAIN DATALOADER\n","train_dataset = TaggingDataset(\n","    sentences=train_sentences,\n","    tags=train_tags,\n","    token_to_idx=token_to_idx,\n","    tag_to_idx=tag_to_idx,\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=32,\n","    shuffle=True,\n","    drop_last=True,\n","    collate_fn=PaddingCollator(\n","        pad_token_id=token_to_idx['<PAD>'],\n","        pad_tag_id=tag_to_idx['O'],\n","        batch_first=True,\n","    ),\n",")\n","\n","# VALIDATION DATALOADER\n","validation_dataset = TaggingDataset(\n","    sentences=val_sentences,\n","    tags=val_tags,\n","    token_to_idx=token_to_idx,\n","    tag_to_idx=tag_to_idx,\n",")\n","\n","validation_loader = DataLoader(\n","    validation_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    drop_last=True,\n","    collate_fn=PaddingCollator(\n","        pad_token_id=token_to_idx['<PAD>'],\n","        pad_tag_id=tag_to_idx['O'],\n","        batch_first=True,\n","    ),\n",")\n","\n","# TEST DATALOADER\n","test_dataset = TaggingDataset(\n","    sentences=test_sentences,\n","    tags=test_tags,\n","    token_to_idx=token_to_idx,\n","    tag_to_idx=tag_to_idx,\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    drop_last=True,\n","    collate_fn=PaddingCollator(\n","        pad_token_id=token_to_idx['<PAD>'],\n","        pad_tag_id=tag_to_idx['O'],\n","        batch_first=True,\n","    ),\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNembuaQCWBe"},"source":["class BiLSTMModel(torch.nn.Module):\n","    def __init__(\n","        self,\n","        vocabulary_size,\n","        tag_space_size,\n","        pad_token_idx,\n","        embedding_dim,\n","        lstm_hidden_size,\n","        dropout_zeroed_probability,\n","        device='cpu'\n","    ):\n","        '''\n","        Defines neural network structure.\n","        \n","        architecture: input -> Embedding -> BiLSTM with Dropout -> Linear\n","        \n","        ----------\n","        Parameters\n","        \n","        vocabulary_size: int, number of words in vocabulary.\n","        tag_space_size: int, number of tags.\n","        pad_token_idx: int, index of padding character. Used for loss masking.\n","        embedding_dim: int, dimension of words' embeddings.\n","        lstm_hidden_size: int, number of hidden units in each LSTM cell\n","        dropout_zeroed_probability: float, dropout zeroed probability for Dropout layer.\n","        device: str, cpu or cuda:x\n","        '''\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocabulary_size, embedding_dim, padding_idx=pad_token_idx)\n","        self.bilstm = nn.LSTM(embedding_dim, hidden_size=lstm_hidden_size, bidirectional = True)\n","        self.device = device\n","        self.dropout = nn.Dropout(dropout_zeroed_probability)\n","        self.linear = nn.Linear(2 * lstm_hidden_size, tag_space_size)\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################        \n","\n","        \n","    def forward(self, x_batch):\n","        '''\n","        Makes forward pass.\n","        \n","        ----------\n","        Parameters\n","        x_batch: torch.LongTensor with shape (number of samples in batch, number words in sentence).\n","        '''\n","        x_batch = torch.LongTensor(x_batch)\n","        out = self.embedding(x_batch)\n","        out, _ = self.bilstm(out)\n","        out = self.dropout(out)\n","        pred_scores = self.linear(out)\n","        #pred_probs = nn.LogSoftmax(pred_scores, dim=2)\n","        return pred_scores\n","\n","\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################        \n","    \n","    def predict_for_batch(self, x_batch):\n","        '''\n","        Returns predictions for x_batch. Use argmax function.\n","        \n","        return type: torch.LongTensor\n","        return shape: (number of samples in batch, number words in sentence.\n","        \n","        ----------\n","        Parameters\n","        x_batch: torch.LongTensor with shape (number of samples in batch, number words in sentence).\n","        '''\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################   \n","        with torch.no_grad():\n","          pred_probs = self.forward(x_batch)\n","          pred_probs  = nn.functional.log_softmax(pred_probs, dim = 2)\n","          pred_tags = torch.argmax(pred_probs, dim = 2)\n","        \n","        return pred_tags\n","\n","\n","    def predict_for_batch_crf(self, x_batch):\n","        '''\n","        Returns predictions for x_batch. Use argmax function.\n","        \n","        return type: torch.LongTensor\n","        return shape: (number of samples in batch, number words in sentence.\n","        \n","        ----------\n","        Parameters\n","        x_batch: torch.LongTensor with shape (number of samples in batch, number words in sentence).\n","        '''\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################   \n","        with torch.no_grad():\n","          pred_probs = self.forward(x_batch)\n","          pred_probs  = nn.functional.log_softmax(pred_probs, dim = 2)\n","          #pred_tags = torch.argmax(pred_probs, dim = 2)\n","        \n","        return pred_probs  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"os4M7P2q-MVX"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knz7h9jgCWBi"},"source":["#from evaluation_ner import ScoreEvaluator\n","\n","evaluator = ScoreEvaluator(\n","    token_to_idx=token_to_idx,\n","    idx_to_tag=idx_to_tag,\n","    idx_to_token=idx_to_token,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgPmfdE6tQsC","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1603617927286,"user_tz":-180,"elapsed":4648,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"e548718e-f4fa-4ba1-8840-cf08aca65900"},"source":["!pip install barbar\n","from barbar import Bar\n","from tqdm import tqdm\n","from torch.optim import Adam\n","#import pytorch_warmup as warmup\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting barbar\n","  Downloading https://files.pythonhosted.org/packages/48/1f/9b69ce144f484cfa00feb09fa752139658961de6303ea592487738d0b53c/barbar-0.2.1-py3-none-any.whl\n","Installing collected packages: barbar\n","Successfully installed barbar-0.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pmviAypJCWBm"},"source":["######################################\n","######### YOUR CODE HERE #############\n","######################################    \n","\n","\n","model = BiLSTMModel(len(token_to_idx),\n","                    len(tag_to_idx),\n","                    token_to_idx['<PAD>'],\n","                    embedding_dim= 150,\n","                    lstm_hidden_size= 200,\n","                    dropout_zeroed_probability= 0.5,\n","                    device = 'cpu' )\n","\n","loss = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=0.01,weight_decay=1e-5)\n","epoch = 20\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZ4c68UPjvBZ"},"source":["\n","def train_model(model, loss, optimizer, epoch, device = 'cpu'):\n","  \n","\n","  num_steps = len(train_loader) * epoch\n","  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\n","  #warmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n","  all_losses_train = []\n","  all_losses_test = []\n","  #device ='cuda'\n","  #model.to('cpu')\n","  print(device)\n","  model.to(device)\n","  model.train()\n","  #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: epoch / 1.1)\n","  for n_epoch in (range(epoch)):\n","      #train part\n","      \n","     \n","      mean_loss_train = 0.0\n","      mean_loss_test = 0.0\n","      print(\" Epoch: {0}/{1}\".format(n_epoch+1, epoch))\n","      print('-' * 10)\n","      print(\"TRAIN FAZE:\")\n","      #scheduler.step()\n","      #print(\"LR: \",scheduler.get_lr()[0])\n","      for token, tag  in (tqdm(train_loader,position=0, leave=True)): \n","\n","          token = token.to(device)\n","          tag = tag.to(device)\n","          optimizer.zero_grad()\n","\n","          outputs = model(token)\n","\n","          loss_value = loss(outputs.permute(0,2,1), tag)\n","          mean_loss_train += loss_value.to('cpu')\n","          loss_value.backward()\n","\n","          #clipping_value = 2 # arbitrary value of your choosing\n","          #torch.nn.utils.clip_grad_norm(model.parameters(), clipping_value)  \n","          \n","          optimizer.step()\n","          lr_scheduler.step()\n","          #warmup_scheduler.dampen()\n","          \n","          \n","          \n","\n","\n","\n","        \n","      epoch_loss_train = mean_loss_train/len(train_loader)\n","      print(\" Loss Train: {0}\".format(epoch_loss_train))\n","      \n","      all_losses_train.append(epoch_loss_train)\n","\n","  import matplotlib.pyplot as plt\n","  plt.plot(all_losses_train,'r')\n","  #plt.plot(all_losses_test,'g')\n","  line_up, = plt.plot(all_losses_train, \"r\", label='train')\n","  #line_down, = plt.plot(all_losses_test, \"g\", label='test')\n","  plt.legend(handles=[line_up])\n","  plt.show()\n","\n","\n","  model.to('cpu')\n","  with torch.no_grad():\n","        model.eval()\n","        print(\"Train metrics\")\n","        evaluator.eval_conll(model,train_loader,print_results=True,short_report=True)\n","\n","        print(\"Test metrics\")\n","        evaluator.eval_conll(model,test_loader,print_results=True,short_report=True)\n","\n","        print(\"Validation metrics\")\n","        evaluator.eval_conll(model,validation_loader,print_results=True,short_report=True)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzhEIaaQkOtC","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1603618519005,"user_tz":-180,"elapsed":594655,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"a1d836ae-884a-4341-90ad-fac69a1ce12b"},"source":["train_model(model, loss,optimizer, epoch, device = 'cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["cpu\n"," Epoch: 1/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.45it/s]\n","  1%|          | 1/181 [00:00<00:27,  6.66it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.29686418175697327\n"," Epoch: 2/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.63it/s]\n","  1%|          | 1/181 [00:00<00:27,  6.63it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.192129448056221\n"," Epoch: 3/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.61it/s]\n","  1%|          | 1/181 [00:00<00:25,  6.98it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.13244137167930603\n"," Epoch: 4/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.63it/s]\n","  1%|          | 1/181 [00:00<00:25,  6.98it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.10057751089334488\n"," Epoch: 5/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.66it/s]\n","  1%|          | 1/181 [00:00<00:25,  7.13it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.08753395825624466\n"," Epoch: 6/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.70it/s]\n","  1%|          | 1/181 [00:00<00:25,  7.13it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.08214685320854187\n"," Epoch: 7/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:27<00:00,  6.56it/s]\n","  1%|          | 1/181 [00:00<00:30,  5.96it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.07866158336400986\n"," Epoch: 8/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:29<00:00,  6.18it/s]\n","  1%|          | 1/181 [00:00<00:30,  5.95it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.07464296370744705\n"," Epoch: 9/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:29<00:00,  6.08it/s]\n","  1%|          | 1/181 [00:00<00:30,  5.88it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.07117990404367447\n"," Epoch: 10/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:30<00:00,  6.02it/s]\n","  1%|          | 1/181 [00:00<00:28,  6.37it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.06816837936639786\n"," Epoch: 11/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:29<00:00,  6.13it/s]\n","  1%|          | 1/181 [00:00<00:30,  5.89it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.06511998176574707\n"," Epoch: 12/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:29<00:00,  6.23it/s]\n","  1%|          | 1/181 [00:00<00:29,  6.16it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.06327037513256073\n"," Epoch: 13/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.24it/s]\n","  1%|          | 1/181 [00:00<00:27,  6.61it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.059832535684108734\n"," Epoch: 14/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.26it/s]\n","  1%|          | 1/181 [00:00<00:27,  6.47it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.058265168219804764\n"," Epoch: 15/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:31<00:00,  5.83it/s]\n","  0%|          | 0/181 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.05564968287944794\n"," Epoch: 16/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:30<00:00,  5.89it/s]\n","  1%|          | 1/181 [00:00<00:28,  6.27it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.05501915141940117\n"," Epoch: 17/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.26it/s]\n","  1%|          | 1/181 [00:00<00:29,  6.07it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.052479326725006104\n"," Epoch: 18/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:29<00:00,  6.24it/s]\n","  1%|          | 1/181 [00:00<00:27,  6.63it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.05110986903309822\n"," Epoch: 19/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.28it/s]\n","  1%|          | 1/181 [00:00<00:28,  6.39it/s]"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.050276339054107666\n"," Epoch: 20/20\n","----------\n","TRAIN FAZE:\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 181/181 [00:28<00:00,  6.25it/s]\n"],"name":"stderr"},{"output_type":"stream","text":[" Loss Train: 0.04933681711554527\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Train metrics\n","processed 105737 tokens with 4487 phrases; found: 5187 phrases; correct: 3190.\n","\n","precision:  61.50%; recall:  71.09%; F1:  65.95\n","\n","Test metrics\n","processed 13258 tokens with 604 phrases; found: 448 phrases; correct: 195.\n","\n","precision:  43.53%; recall:  32.28%; F1:  37.07\n","\n","Validation metrics\n","processed 12473 tokens with 526 phrases; found: 382 phrases; correct: 166.\n","\n","precision:  43.46%; recall:  31.56%; F1:  36.56\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cLSftbY_F9Ad"},"source":["\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJuWdCIv8iRa","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1603618519017,"user_tz":-180,"elapsed":593370,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"00c082e2-c0a9-41f0-ab91-19d547d95b4c"},"source":["'''with torch.no_grad():\n","  i = 3\n","  model.eval()\n","  t = validation_dataset[i][0].long()\n","  print(val_sentences[i])\n","  #print(validation_dataset[0][0])\n","  #print(train_dataset[0])\n","  temp_ouput = model.predict_for_batch(t.unsqueeze(0)).tolist()[0]\n","  print(temp_ouput)\n","  answer = [   idx_to_tag[i]  for i in temp_ouput]\n","  print(answer)\n","  print(validation_dataset[i][1])'''\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'with torch.no_grad():\\n  i = 3\\n  model.eval()\\n  t = validation_dataset[i][0].long()\\n  print(val_sentences[i])\\n  #print(validation_dataset[0][0])\\n  #print(train_dataset[0])\\n  temp_ouput = model.predict_for_batch(t.unsqueeze(0)).tolist()[0]\\n  print(temp_ouput)\\n  answer = [   idx_to_tag[i]  for i in temp_ouput]\\n  print(answer)\\n  print(validation_dataset[i][1])'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"iQ1LsCNQ9VZw","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1603618519019,"user_tz":-180,"elapsed":592743,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"a4d3e112-e142-4fe4-8b04-f187ad212e75"},"source":["'''\n","model.eval()\n","torch.save(model.state_dict(), \"/content/model.pt\")\n","\n","model = model = BiLSTMModel(len(token_to_idx),\n","                    len(tag_to_idx),\n","                    token_to_idx['<PAD>'],\n","                    embedding_dim= 150,\n","                    lstm_hidden_size= 180,\n","                    dropout_zeroed_probability= 0.5,\n","                    device = 'cpu' )\n","\n","model.load_state_dict(torch.load(\"/content/model.pt\"))\n","model.eval()'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nmodel.eval()\\ntorch.save(model.state_dict(), \"/content/model.pt\")\\n\\nmodel = model = BiLSTMModel(len(token_to_idx),\\n                    len(tag_to_idx),\\n                    token_to_idx[\\'<PAD>\\'],\\n                    embedding_dim= 150,\\n                    lstm_hidden_size= 180,\\n                    dropout_zeroed_probability= 0.5,\\n                    device = \\'cpu\\' )\\n\\nmodel.load_state_dict(torch.load(\"/content/model.pt\"))\\nmodel.eval()'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"KJTgdXKcCWBr"},"source":["from collections import Counter\n","from itertools import combinations_with_replacement\n","import math\n","\n","class ViterbiPostprocesser:    \n","    def __init__(self, model, smoothing=1.0, w=1.0):\n","        \"\"\"\n","        model : torch.nn.Module\n","            Tagging model\n","        smoothing : float, constant in add-k-smoothing\n","        w : feature weight\n","             Use w for first feature weight and (1 - w) for second feature.\n","        \"\"\"\n","        self.model = model\n","        self.smoothing = smoothing\n","        self.w1 = w\n","        self.w2 = 1-w\n","        self.A = 0\n","        self.C = 0\n","        self.tags_ar = 0\n","\n","        self.increm = 1\n","        \n","        \n","    def fit(self, dataset):\n","        \"\"\"\n","        Fit the model using maximum likelihood method.\n","        \n","        dataset: torch.dataset\n","            One element if pair (sentence, tags) \n","        \"\"\"\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################  \n","        token,tag = zip(*dataset)\n","\n","        self.tags_ar  = torch.unique(torch.cat(list(tag))).tolist()\n","        \n","        self.A = torch.zeros([len(self.tags_ar), len(self.tags_ar)], dtype=torch.float64)\n","        #print(self.A)\n","        list_pairs = list(combinations_with_replacement(self.tags_ar,2))\n","        #print(list_pairs)\n","        sequence = torch.cat(list(tag)).tolist()\n","        #print(sequence)\n","        c = dict(Counter(zip(sequence, sequence[1:])))\n","        #print(dict(c))\n","        #[1, 2, 3, 4, 1, 4, 1].count(1)  \n","        for i,j in list_pairs:\n","            \n","            if (i==j):\n","\n","              if ((i,j) in c):\n","                counts = c[(i,j)]\n","              else:\n","                counts = 0.0\n","\n","              self.A[i][j] = (counts+self.smoothing)/(sequence.count(j) + len(sequence)*self.smoothing)\n","              \n","            else: \n","              \n","              if ((j,i) in c):\n","                counts = c[(j,i)]\n","              else:\n","                counts = 0.0\n","\n","              self.A[i][j] = (counts+self.smoothing)/(sequence.count(j) + len(sequence)*self.smoothing)\n","\n","              if ((i,j) in c):\n","                counts = c[(i,j)]\n","              else:\n","                counts = 0.0\n","\n","              self.A[j][i] = (counts+self.smoothing)/(sequence.count(i) + len(sequence)*self.smoothing)\n","\n","        self.C = [sequence.count(i)/len(sequence) for i in self.tags_ar] \n","\n","        #print(self.A)\n","        #print(self.C)\n","\n","        \n","    def decode(self, model_logprobs):\n","        \"\"\"\n","        Viterbi decoding for input model output\n","        \n","        model_logprobs : torch.tensor\n","            Shape is (sequence_length, tag_space_size) \n","        \"\"\"\n","        #print(model_logprobs.shape)\n","        sequence_length = list(model_logprobs.shape)[0]\n","        tag_space_size = list(model_logprobs.shape)[1]\n","        #print(model_logprobs.shape)\n","        #print(sequence_length)\n","        #print(tag_space_size)\n","\n","        def f1(y,i):\n","          return model_logprobs[i][y]\n","        \n","        def f2(x,y,i):\n","          return math.log(self.C[y]) if i<1 else math.log(self.A[x][y])\n","\n","\n","        \n","        def G(u,v,k):\n","          return self.w1 * f1(v,k)+ self.w2 * f2(u,v,k)\n","\n","        def straight_step(i,j,U_row):\n","          arr_proba = []\n","          for elem in self.tags_ar:\n","            arr_proba.append(G(elem,j,i)+U_row[elem])\n","          return max(arr_proba)\n","                  \n","        U = torch.zeros([sequence_length+1, tag_space_size], dtype=torch.float64)\n","\n","        for i in range(1,sequence_length+1):\n","          for j in range(0,tag_space_size):\n","            U[i,j] = straight_step(i-1,j,U[i-1])\n","\n","        final_tag_ids = [-1]\n","\n","        def reverse_step(U_row, flag_it, previous_tag_final, increment):\n","          arr_max = []\n","          if (flag_it):\n","            values, indices = torch.max(U_row, 0)\n","            return indices.item()\n","          else:\n","            for i in self.tags_ar:\n","              arr_max.append(U_row[i]+G(i,previous_tag_final,increment+1))\n","            values, indices = torch.max(torch.Tensor(arr_max), 0)\n","            return indices.item()\n","            \n","            \n","        flag_check = True\n","        for tag_inc in reversed(range(1,sequence_length+1)):\n","          tmp = reverse_step(U[tag_inc], flag_check, final_tag_ids[-1], tag_inc-1)\n","          final_tag_ids.append(tmp)\n","          flag_check = False\n","\n","        final_tag_ids.reverse()\n","        tmp_res = final_tag_ids[:-1]\n","        #print(torch.Tensor(tmp_res).shape)\n","\n","        \n","        return torch.Tensor(tmp_res)\n","\n","\n","\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ######################################        \n","    \n","    def predict_for_batch(self, x_batch):\n","        \"\"\"\n","        Returns predictions for x_batch. Use viterbi decoding.\n","        \n","        return type: torch.LongTensor\n","        return shape: (number of samples in batch, number words in sentence.\n","        \n","        ----------\n","        Parameters\n","        x_batch: torch.LongTensor with shape (number of samples in batch, number words in sentence).\n","        \"\"\"\n","\n","\n","        ######################################\n","        ######### YOUR CODE HERE #############\n","        ###################################### \n","        self.model.eval()\n","        with torch.no_grad():\n","          #result_tensor = torch.zeros([x_batch.size(0), x_batch.size(1)], dtype=torch.float64)\n","          tensor_ar = []\n","          \n","          output = self.model.predict_for_batch_crf(x_batch)\n","          for i in output:\n","            tensor_ar.append(self.decode(i))\n","          result = torch.stack(tensor_ar).long()\n","          #print(result.shape)\n","          #print(x_batch.shape)\n","         # print(\"Batch {} passed\".format(self.increm))\n","          self.increm+=1\n","          \n","          \n","          return result      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4P0-MNjgCWBw"},"source":["Место для ваших экспериментов:"]},{"cell_type":"code","metadata":{"id":"NDyuOp8hCWBy","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1603626601085,"user_tz":-180,"elapsed":587013,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"0c62a316-3df0-4d75-b8c3-7ca3634c3ba5"},"source":["VP = ViterbiPostprocesser(model,smoothing=1.0,w = 0.99)\n","VP.fit(train_dataset)\n","#print(\"Train metrics\")\n","#evaluator.eval_conll(VP,train_loader,print_results=True,short_report=True)\n","\n","print(\"Test metrics\")\n","evaluator.eval_conll(VP,test_loader,print_results=True,short_report=True)\n","\n","print(\"Validation metrics\")\n","evaluator.eval_conll(VP,validation_loader,print_results=True,short_report=True)\n","  \n","    ######################################\n","    ######### YOUR CODE HERE #############\n","    ######################################       "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test metrics\n","Batch 1 passed\n","Batch 2 passed\n","Batch 3 passed\n","Batch 4 passed\n","Batch 5 passed\n","Batch 6 passed\n","Batch 7 passed\n","Batch 8 passed\n","Batch 9 passed\n","Batch 10 passed\n","Batch 11 passed\n","Batch 12 passed\n","Batch 13 passed\n","Batch 14 passed\n","Batch 15 passed\n","Batch 16 passed\n","Batch 17 passed\n","Batch 18 passed\n","Batch 19 passed\n","Batch 20 passed\n","Batch 21 passed\n","Batch 22 passed\n","Batch 23 passed\n","Batch 24 passed\n","Batch 25 passed\n","Batch 26 passed\n","Batch 27 passed\n","Batch 28 passed\n","Batch 29 passed\n","Batch 30 passed\n","Batch 31 passed\n","Batch 32 passed\n","Batch 33 passed\n","Batch 34 passed\n","Batch 35 passed\n","Batch 36 passed\n","Batch 37 passed\n","Batch 38 passed\n","Batch 39 passed\n","Batch 40 passed\n","Batch 41 passed\n","Batch 42 passed\n","Batch 43 passed\n","Batch 44 passed\n","Batch 45 passed\n","Batch 46 passed\n","Batch 47 passed\n","Batch 48 passed\n","Batch 49 passed\n","Batch 50 passed\n","Batch 51 passed\n","Batch 52 passed\n","Batch 53 passed\n","Batch 54 passed\n","Batch 55 passed\n","Batch 56 passed\n","Batch 57 passed\n","Batch 58 passed\n","Batch 59 passed\n","Batch 60 passed\n","Batch 61 passed\n","Batch 62 passed\n","Batch 63 passed\n","Batch 64 passed\n","Batch 65 passed\n","Batch 66 passed\n","Batch 67 passed\n","Batch 68 passed\n","Batch 69 passed\n","Batch 70 passed\n","Batch 71 passed\n","Batch 72 passed\n","Batch 73 passed\n","Batch 74 passed\n","Batch 75 passed\n","Batch 76 passed\n","Batch 77 passed\n","Batch 78 passed\n","Batch 79 passed\n","Batch 80 passed\n","Batch 81 passed\n","Batch 82 passed\n","Batch 83 passed\n","Batch 84 passed\n","Batch 85 passed\n","Batch 86 passed\n","Batch 87 passed\n","Batch 88 passed\n","Batch 89 passed\n","Batch 90 passed\n","Batch 91 passed\n","Batch 92 passed\n","Batch 93 passed\n","Batch 94 passed\n","Batch 95 passed\n","Batch 96 passed\n","Batch 97 passed\n","Batch 98 passed\n","Batch 99 passed\n","Batch 100 passed\n","Batch 101 passed\n","Batch 102 passed\n","Batch 103 passed\n","Batch 104 passed\n","Batch 105 passed\n","Batch 106 passed\n","Batch 107 passed\n","Batch 108 passed\n","Batch 109 passed\n","Batch 110 passed\n","Batch 111 passed\n","Batch 112 passed\n","Batch 113 passed\n","Batch 114 passed\n","Batch 115 passed\n","Batch 116 passed\n","Batch 117 passed\n","Batch 118 passed\n","Batch 119 passed\n","Batch 120 passed\n","Batch 121 passed\n","Batch 122 passed\n","Batch 123 passed\n","Batch 124 passed\n","Batch 125 passed\n","Batch 126 passed\n","Batch 127 passed\n","Batch 128 passed\n","Batch 129 passed\n","Batch 130 passed\n","Batch 131 passed\n","Batch 132 passed\n","Batch 133 passed\n","Batch 134 passed\n","Batch 135 passed\n","Batch 136 passed\n","Batch 137 passed\n","Batch 138 passed\n","Batch 139 passed\n","Batch 140 passed\n","Batch 141 passed\n","Batch 142 passed\n","Batch 143 passed\n","Batch 144 passed\n","Batch 145 passed\n","Batch 146 passed\n","Batch 147 passed\n","Batch 148 passed\n","Batch 149 passed\n","Batch 150 passed\n","Batch 151 passed\n","Batch 152 passed\n","Batch 153 passed\n","Batch 154 passed\n","Batch 155 passed\n","Batch 156 passed\n","Batch 157 passed\n","Batch 158 passed\n","Batch 159 passed\n","Batch 160 passed\n","Batch 161 passed\n","Batch 162 passed\n","Batch 163 passed\n","Batch 164 passed\n","Batch 165 passed\n","Batch 166 passed\n","Batch 167 passed\n","Batch 168 passed\n","Batch 169 passed\n","Batch 170 passed\n","Batch 171 passed\n","Batch 172 passed\n","Batch 173 passed\n","Batch 174 passed\n","Batch 175 passed\n","Batch 176 passed\n","Batch 177 passed\n","Batch 178 passed\n","Batch 179 passed\n","Batch 180 passed\n","Batch 181 passed\n","processed 13258 tokens with 604 phrases; found: 429 phrases; correct: 197.\n","\n","precision:  45.92%; recall:  32.62%; F1:  38.14\n","\n","Validation metrics\n","Batch 182 passed\n","Batch 183 passed\n","Batch 184 passed\n","Batch 185 passed\n","Batch 186 passed\n","Batch 187 passed\n","Batch 188 passed\n","Batch 189 passed\n","Batch 190 passed\n","Batch 191 passed\n","Batch 192 passed\n","processed 12450 tokens with 521 phrases; found: 373 phrases; correct: 167.\n","\n","precision:  44.77%; recall:  32.05%; F1:  37.36\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'f1': 37.36017897091723,\n"," 'n_predicted_entities': 373,\n"," 'n_true_entities': 521,\n"," 'precision': 44.77211796246649,\n"," 'recall': 32.05374280230326}"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"CRTNYbQUpKTO"},"source":["Улучшение результатов на целый процент!! По F1 мере для теста и валидации !!!"]},{"cell_type":"code","metadata":{"id":"oJIwsGslvFbU","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1603629189578,"user_tz":-180,"elapsed":4713,"user":{"displayName":"Александр Сомик","photoUrl":"","userId":"17519054358021298804"}},"outputId":"e10cffe5-8352-4ad1-a990-91c802a0cd42"},"source":["valida = TaggingDataset(\n","    sentences=val_sentences[:10],\n","    tags=val_tags[:10],\n","    token_to_idx=token_to_idx,\n","    tag_to_idx=tag_to_idx,\n",")\n","\n","valida_loader = DataLoader(\n","    valida,\n","    batch_size=10,\n","    shuffle=False,\n","    drop_last=False,\n","    collate_fn=PaddingCollator(\n","        pad_token_id=token_to_idx['<PAD>'],\n","        pad_tag_id=tag_to_idx['O'],\n","        batch_first=True,\n","    ),\n",")\n","\n","for i,j in valida_loader:\n","  output = VP.predict_for_batch(i)\n","k = 4\n","\n","print(val_tags[k])\n","print(j[k])\n","print(\"compare\")\n","print(output[k])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Batch 206 passed\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-other', 'O']\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0])\n","compare\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0VuMUbIo48RZ"},"source":["\n","#fit part\n","'''\n","token,tag = zip(*train_dataset)\n","tags_ar  = torch.unique(torch.cat(list(tag)))\n","print(type(tags_ar))\n","\n","\n","from itertools import combinations\n","token,tag = zip(*train_dataset)\n","tags_ar  = torch.unique(torch.cat(list(tag))).tolist()\n","A = torch.zeros([len(tags_ar), len(tags_ar)], dtype=torch.float64)\n","list_pairs = list(combinations_with_replacement(tags_ar,2))\n","print(list_pairs)\n","from collections import Counter\n","sequence = torch.cat(list(tag)).tolist()[:10]\n","#print(sequence)\n","c = Counter(zip(sequence, sequence[1:]))\n","print(dict(c))\n","[1, 2, 3, 4, 1, 4, 1].count(1)\n","\n","#print(sequence.count(tags_ar[1]))\n","C_matrix = [sequence.count(i)/len(sequence) for i in tags_ar] \n","print(C_matrix)\n","'''\n"],"execution_count":null,"outputs":[]}]}